#!/usr/bin/env bash
# =============================================================================
# Platform Hydration Script
# =============================================================================
# One-time setup script to bootstrap the EKS platform infrastructure.
# Run this before the first terraform apply.
#
# WHAT THIS DOES:
# ---------------
#   1. Creates S3 bucket for Terraform state
#   2. Creates DynamoDB table for state locking
#   3. Creates IAM OIDC provider for GitHub Actions (keyless auth)
#   4. Creates IAM role for GitHub Actions to assume
#   5. Sets GitHub repository secrets
#   6. Captures admin IP and IAM role for access control
#   7. Generates ArgoCD deploy key for Git repo access
#   8. Saves configuration for cleanup script
#   9. Optionally triggers Terraform Apply via GitHub Actions [Y/n]
#
# NOTE: FortiWeb credentials are auto-generated by Terraform using the
#       random provider - no manual password entry required.
#
# PREREQUISITES:
# --------------
#   - AWS CLI configured with admin credentials
#   - GitHub CLI (gh) authenticated
#   - jq installed
#
# USAGE:
#   ./bootstrap/hydrate.sh [options]
#
# OPTIONS:
#   --help                  Show this help message
#   --set-fortiflex-token   Only set the FortiFlex token in GitHub secrets
#   --set-delegation-set    Create/retrieve reusable delegation set for DNS
#
# =============================================================================
set -euo pipefail

# Disable AWS CLI pager (prevents opening less/more)
export AWS_PAGER=""

# Disable GitHub CLI prompts
export GH_PROMPT_DISABLED=1

# -----------------------------------------------------------------------------
# Configuration
# -----------------------------------------------------------------------------
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_NAME="${PROJECT_NAME:-xperts}"
ENVIRONMENT="${ENVIRONMENT:-dev}"
AWS_REGION="${AWS_REGION:-ca-central-1}"
GITHUB_ORG="${GITHUB_ORG:-amerintlxperts}"
GITHUB_REPO="${GITHUB_REPO:-infrastructure-2026}"

# DNS Configuration (set here to skip prompts)
DOMAIN_NAME="${DOMAIN_NAME:-}"
ACME_EMAIL="${ACME_EMAIL:-}"
DELEGATION_SET_ID="${DELEGATION_SET_ID:-N04333643VKH12NIINQ7I}"  # Reusable delegation set from 40docs (same AWS account)

# Derived names
STATE_BUCKET="${PROJECT_NAME}-terraform-state-${AWS_REGION}"
LOCK_TABLE="${PROJECT_NAME}-terraform-locks"
OIDC_ROLE_NAME="${PROJECT_NAME}-github-actions"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# -----------------------------------------------------------------------------
# Helper Functions
# -----------------------------------------------------------------------------
log_info() { echo -e "${GREEN}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

check_command() {
  if ! command -v "$1" &> /dev/null; then
    log_error "$1 is required but not installed."
    exit 1
  fi
}

show_help() {
  cat << 'EOF'
Platform Hydration Script
=========================

One-time setup script to bootstrap the EKS platform infrastructure.
Run this before the first terraform apply.

USAGE:
  ./bootstrap/hydrate.sh [options]

OPTIONS:
  --help                  Show this help message
  --set-fortiflex-token   Only set/update the FortiFlex token in GitHub secrets
                          (useful when token expires or needs rotation)
  --set-delegation-set    Create a reusable delegation set for consistent Route53
                          nameservers across destroy/recreate cycles. Run once,
                          then update your domain registrar with the nameservers.

WHAT THIS DOES (full hydration):
  1. Creates S3 bucket for Terraform state
  2. Creates DynamoDB table for state locking
  3. Creates IAM OIDC provider for GitHub Actions (keyless auth)
  4. Creates IAM role for GitHub Actions to assume
  5. Sets GitHub repository secrets
  6. Captures admin IP, IAM role, DNS config, and optional secrets:
     - FortiFlex token (FortiWeb licensing)
     - Chatbot htpasswd (basic auth)
     - ghcr.io pull secret (private container images)
  7. Generates ArgoCD deploy keys for Git repo access (main + additional)
  8. Saves configuration for cleanup script
  9. Optionally triggers Terraform Apply via GitHub Actions

NOTE: FortiWeb credentials are auto-generated by Terraform (no manual input)

PREREQUISITES:
  - AWS CLI configured with admin credentials
  - GitHub CLI (gh) authenticated
  - jq installed

ENVIRONMENT VARIABLES:
  PROJECT_NAME       Project name prefix (default: xperts)
  ENVIRONMENT        Environment name (default: dev)
  AWS_REGION         AWS region (default: ca-central-1)
  GITHUB_ORG         GitHub organization (default: amerintlxperts)
  GITHUB_REPO        GitHub repository (default: infrastructure-2026)
  DOMAIN_NAME        Domain name for Route53 (prompts if not set)
  ACME_EMAIL         Email for Let's Encrypt (prompts if not set)
  DELEGATION_SET_ID  Reusable delegation set ID (created if not set)

EXAMPLES:
  # Full hydration (first-time setup)
  ./bootstrap/hydrate.sh

  # Update FortiFlex token only
  ./bootstrap/hydrate.sh --set-fortiflex-token

  # Create reusable delegation set for consistent nameservers
  ./bootstrap/hydrate.sh --set-delegation-set

  # Use different project name
  PROJECT_NAME=myproject ./bootstrap/hydrate.sh

EOF
  exit 0
}

# -----------------------------------------------------------------------------
# Argument Parsing
# -----------------------------------------------------------------------------
SET_FORTIFLEX_ONLY=false
SET_DELEGATION_SET=false

while [[ $# -gt 0 ]]; do
  case $1 in
    --help|-h)
      show_help
      ;;
    --set-fortiflex-token)
      SET_FORTIFLEX_ONLY=true
      shift
      ;;
    --set-delegation-set)
      SET_DELEGATION_SET=true
      shift
      ;;
    *)
      log_error "Unknown option: $1"
      echo "Use --help for usage information"
      exit 1
      ;;
  esac
done

# -----------------------------------------------------------------------------
# FortiFlex Token Only Mode
# -----------------------------------------------------------------------------
if [[ "$SET_FORTIFLEX_ONLY" == "true" ]]; then
  log_info "FortiFlex token update mode"

  check_command gh

  # Verify GitHub CLI auth
  if ! gh auth status &> /dev/null; then
    log_error "GitHub CLI not authenticated. Run 'gh auth login'"
    exit 1
  fi

  log_info "GitHub: ${GITHUB_ORG}/${GITHUB_REPO}"

  echo ""
  echo "FortiFlex licensing for FortiWeb:"
  echo "  - Leave blank to remove existing token (use PAYG)"
  echo "  - Enter token for FortiFlex/BYOL licensing"
  read -p "  FortiFlex Token [skip]: " FORTIFLEX_TOKEN

  if [[ -n "$FORTIFLEX_TOKEN" ]]; then
    gh secret set TF_VAR_fortiflex_token --body "${FORTIFLEX_TOKEN}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
    log_info "Set GitHub secret TF_VAR_fortiflex_token"
  else
    gh secret delete TF_VAR_fortiflex_token --repo "${GITHUB_ORG}/${GITHUB_REPO}" 2>/dev/null || true
    log_info "Removed FortiFlex token (using PAYG or manual licensing)"
  fi

  echo ""
  log_info "FortiFlex token updated successfully!"
  echo ""
  echo "Note: Run 'terraform apply' or trigger GitHub Actions to apply the change."
  exit 0
fi

# -----------------------------------------------------------------------------
# Reusable Delegation Set Mode
# -----------------------------------------------------------------------------
# Creates a reusable delegation set for consistent Route53 nameservers.
# This ensures nameservers don't change when you destroy/recreate infrastructure.
# -----------------------------------------------------------------------------
if [[ "$SET_DELEGATION_SET" == "true" ]]; then
  log_info "Reusable delegation set mode"

  check_command aws
  check_command gh
  check_command jq

  # Verify AWS credentials
  if ! aws sts get-caller-identity &> /dev/null; then
    log_error "AWS credentials not configured. Run 'aws configure' or 'aws sso login'"
    exit 1
  fi

  # Verify GitHub CLI auth
  if ! gh auth status &> /dev/null; then
    log_error "GitHub CLI not authenticated. Run 'gh auth login'"
    exit 1
  fi

  log_info "GitHub: ${GITHUB_ORG}/${GITHUB_REPO}"

  # Check if delegation set ID is already configured
  if [[ -n "$DELEGATION_SET_ID" ]]; then
    log_info "Using pre-configured delegation set: ${DELEGATION_SET_ID}"
  else
    # Check if we already have a delegation set for this project
    DELEGATION_SET_REF="${PROJECT_NAME}-${ENVIRONMENT}"

    log_info "Looking for existing delegation set with reference: ${DELEGATION_SET_REF}"

    EXISTING_SET=$(aws route53 list-reusable-delegation-sets \
      --query "DelegationSets[?CallerReference=='${DELEGATION_SET_REF}'].Id" \
      --output text 2>/dev/null || true)

    if [[ -n "$EXISTING_SET" && "$EXISTING_SET" != "None" ]]; then
      # Extract just the ID part (remove /delegationset/ prefix if present)
      DELEGATION_SET_ID=$(echo "$EXISTING_SET" | sed 's|/delegationset/||')
      log_info "Found existing delegation set: ${DELEGATION_SET_ID}"
    else
      log_info "Creating new reusable delegation set..."

      CREATE_RESULT=$(aws route53 create-reusable-delegation-set \
        --caller-reference "${DELEGATION_SET_REF}" \
        --output json 2>&1)

      if [[ $? -ne 0 ]]; then
        log_error "Failed to create delegation set: ${CREATE_RESULT}"
        exit 1
      fi

      DELEGATION_SET_ID=$(echo "$CREATE_RESULT" | jq -r '.DelegationSet.Id' | sed 's|/delegationset/||')
      log_info "Created delegation set: ${DELEGATION_SET_ID}"
    fi
  fi

  # Get the nameservers for this delegation set
  NAMESERVERS=$(aws route53 get-reusable-delegation-set \
    --id "${DELEGATION_SET_ID}" \
    --query 'DelegationSet.NameServers' \
    --output json)

  # Store delegation set ID as GitHub secret
  gh secret set TF_VAR_delegation_set_id --body "${DELEGATION_SET_ID}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
  log_info "Set GitHub secret TF_VAR_delegation_set_id=${DELEGATION_SET_ID}"

  # Update .hydration-config if it exists
  CONFIG_FILE="${SCRIPT_DIR}/.hydration-config"
  if [[ -f "$CONFIG_FILE" ]]; then
    # Check if DELEGATION_SET_ID line exists
    if grep -q "^DELEGATION_SET_ID=" "$CONFIG_FILE"; then
      # Update existing line
      sed -i "s/^DELEGATION_SET_ID=.*/DELEGATION_SET_ID=\"${DELEGATION_SET_ID}\"/" "$CONFIG_FILE"
    else
      # Add new line before HYDRATION_DATE
      sed -i "/^HYDRATION_DATE=/i DELEGATION_SET_ID=\"${DELEGATION_SET_ID}\"" "$CONFIG_FILE"
    fi
    log_info "Updated .hydration-config with delegation set ID"
  fi

  echo ""
  log_info "=========================================="
  log_info "Reusable Delegation Set Created!"
  log_info "=========================================="
  echo ""
  echo "Delegation Set ID: ${DELEGATION_SET_ID}"
  echo ""
  echo "IMPORTANT: Update your domain registrar's nameservers to:"
  echo "$NAMESERVERS" | jq -r '.[]' | while read ns; do echo "  - $ns"; done
  echo ""
  echo "These nameservers will NEVER change, even after terraform destroy/apply."
  echo "You only need to update your registrar ONCE."
  echo ""
  echo "Next steps:"
  echo "  1. Log in to your domain registrar (GoDaddy, etc.)"
  echo "  2. Find DNS/Nameserver settings for your domain"
  echo "  3. Replace the current nameservers with the ones above"
  echo "  4. Wait for DNS propagation (up to 48 hours)"
  echo "  5. Run 'terraform apply' or trigger GitHub Actions"
  echo ""
  exit 0
fi

# -----------------------------------------------------------------------------
# Preflight Checks (Full Hydration)
# -----------------------------------------------------------------------------
log_info "Running preflight checks..."

check_command aws
check_command gh
check_command jq

# Verify AWS credentials
if ! aws sts get-caller-identity &> /dev/null; then
  log_error "AWS credentials not configured. Run 'aws configure' or 'aws sso login'"
  exit 1
fi

# Verify GitHub CLI auth
if ! gh auth status &> /dev/null; then
  log_error "GitHub CLI not authenticated. Run 'gh auth login'"
  exit 1
fi

AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
log_info "AWS Account: ${AWS_ACCOUNT_ID}"
log_info "AWS Region: ${AWS_REGION}"
log_info "GitHub: ${GITHUB_ORG}/${GITHUB_REPO}"

# -----------------------------------------------------------------------------
# Step 1: Create S3 Bucket for Terraform State
# -----------------------------------------------------------------------------
log_info "Step 1: Creating S3 bucket for Terraform state..."

if aws s3api head-bucket --bucket "${STATE_BUCKET}" 2>/dev/null; then
  log_warn "Bucket ${STATE_BUCKET} already exists, skipping creation"
else
  aws s3api create-bucket \
    --bucket "${STATE_BUCKET}" \
    --region "${AWS_REGION}" \
    --create-bucket-configuration LocationConstraint="${AWS_REGION}"

  # Enable versioning
  aws s3api put-bucket-versioning \
    --bucket "${STATE_BUCKET}" \
    --versioning-configuration Status=Enabled

  # Enable encryption
  aws s3api put-bucket-encryption \
    --bucket "${STATE_BUCKET}" \
    --server-side-encryption-configuration '{
      "Rules": [{
        "ApplyServerSideEncryptionByDefault": {
          "SSEAlgorithm": "AES256"
        }
      }]
    }'

  # Block public access
  aws s3api put-public-access-block \
    --bucket "${STATE_BUCKET}" \
    --public-access-block-configuration '{
      "BlockPublicAcls": true,
      "IgnorePublicAcls": true,
      "BlockPublicPolicy": true,
      "RestrictPublicBuckets": true
    }'

  log_info "Created S3 bucket: ${STATE_BUCKET}"
fi

# -----------------------------------------------------------------------------
# Step 2: Create DynamoDB Table for State Locking
# -----------------------------------------------------------------------------
log_info "Step 2: Creating DynamoDB table for state locking..."

if aws dynamodb describe-table --table-name "${LOCK_TABLE}" --region "${AWS_REGION}" 2>/dev/null; then
  log_warn "Table ${LOCK_TABLE} already exists, skipping creation"
else
  aws dynamodb create-table \
    --table-name "${LOCK_TABLE}" \
    --attribute-definitions AttributeName=LockID,AttributeType=S \
    --key-schema AttributeName=LockID,KeyType=HASH \
    --billing-mode PAY_PER_REQUEST \
    --region "${AWS_REGION}"

  log_info "Created DynamoDB table: ${LOCK_TABLE}"
fi

# -----------------------------------------------------------------------------
# Step 3: Create GitHub OIDC Provider in AWS
# -----------------------------------------------------------------------------
log_info "Step 3: Creating GitHub OIDC provider in AWS..."

OIDC_PROVIDER_ARN="arn:aws:iam::${AWS_ACCOUNT_ID}:oidc-provider/token.actions.githubusercontent.com"

if aws iam get-open-id-connect-provider --open-id-connect-provider-arn "${OIDC_PROVIDER_ARN}" 2>/dev/null; then
  log_warn "GitHub OIDC provider already exists, skipping creation"
else
  # Get GitHub's OIDC thumbprint
  THUMBPRINT=$(openssl s_client -servername token.actions.githubusercontent.com \
    -connect token.actions.githubusercontent.com:443 < /dev/null 2>/dev/null \
    | openssl x509 -fingerprint -sha1 -noout \
    | cut -d= -f2 | tr -d ':' | tr '[:upper:]' '[:lower:]')

  aws iam create-open-id-connect-provider \
    --url "https://token.actions.githubusercontent.com" \
    --client-id-list "sts.amazonaws.com" \
    --thumbprint-list "${THUMBPRINT}"

  log_info "Created GitHub OIDC provider"
fi

# -----------------------------------------------------------------------------
# Step 4: Create IAM Role for GitHub Actions
# -----------------------------------------------------------------------------
log_info "Step 4: Creating IAM role for GitHub Actions..."

ROLE_ARN="arn:aws:iam::${AWS_ACCOUNT_ID}:role/${OIDC_ROLE_NAME}"

if aws iam get-role --role-name "${OIDC_ROLE_NAME}" 2>/dev/null; then
  log_warn "Role ${OIDC_ROLE_NAME} already exists, skipping creation"
else
  # Trust policy - allow GitHub Actions from this repo to assume the role
  TRUST_POLICY=$(cat <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "${OIDC_PROVIDER_ARN}"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "token.actions.githubusercontent.com:aud": "sts.amazonaws.com"
        },
        "StringLike": {
          "token.actions.githubusercontent.com:sub": "repo:${GITHUB_ORG}/${GITHUB_REPO}:*"
        }
      }
    }
  ]
}
EOF
)

  aws iam create-role \
    --role-name "${OIDC_ROLE_NAME}" \
    --assume-role-policy-document "${TRUST_POLICY}"

  # Create least-privilege policy for Terraform operations
  POLICY_NAME="${OIDC_ROLE_NAME}-policy"
  POLICY_DOCUMENT=$(cat <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "TerraformStateAccess",
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:ListBucket",
        "s3:GetBucketVersioning",
        "s3:PutObjectTagging",
        "s3:GetObjectTagging",
        "s3:ListBucketVersions",
        "s3:DeleteObjectVersion"
      ],
      "Resource": [
        "arn:aws:s3:::${STATE_BUCKET}",
        "arn:aws:s3:::${STATE_BUCKET}/*"
      ]
    },
    {
      "Sid": "TerraformStateLocking",
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:DeleteItem",
        "dynamodb:DescribeTable"
      ],
      "Resource": "arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/${LOCK_TABLE}"
    },
    {
      "Sid": "EKSManagement",
      "Effect": "Allow",
      "Action": [
        "eks:*"
      ],
      "Resource": "*"
    },
    {
      "Sid": "VPCAndNetworking",
      "Effect": "Allow",
      "Action": [
        "ec2:*Vpc*",
        "ec2:*Subnet*",
        "ec2:*RouteTable*",
        "ec2:*InternetGateway*",
        "ec2:*NatGateway*",
        "ec2:*SecurityGroup*",
        "ec2:*NetworkInterface*",
        "ec2:*Address*",
        "ec2:*Instance*",
        "ec2:*Image*",
        "ec2:*Tags*",
        "ec2:*KeyPair*",
        "ec2:*VpcEndpoint*",
        "ec2:*LaunchTemplate*",
        "ec2:*Route",
        "ec2:Describe*",
        "ec2:CreateTags",
        "ec2:DeleteTags"
      ],
      "Resource": "*"
    },
    {
      "Sid": "IAMForIRSA",
      "Effect": "Allow",
      "Action": [
        "iam:CreateRole",
        "iam:DeleteRole",
        "iam:GetRole",
        "iam:PassRole",
        "iam:TagRole",
        "iam:UntagRole",
        "iam:UpdateRole",
        "iam:AttachRolePolicy",
        "iam:DetachRolePolicy",
        "iam:PutRolePolicy",
        "iam:DeleteRolePolicy",
        "iam:GetRolePolicy",
        "iam:ListRolePolicies",
        "iam:ListAttachedRolePolicies",
        "iam:ListInstanceProfilesForRole",
        "iam:CreatePolicy",
        "iam:DeletePolicy",
        "iam:GetPolicy",
        "iam:GetPolicyVersion",
        "iam:ListPolicyVersions",
        "iam:CreateOpenIDConnectProvider",
        "iam:DeleteOpenIDConnectProvider",
        "iam:GetOpenIDConnectProvider",
        "iam:TagOpenIDConnectProvider"
      ],
      "Resource": "*"
    },
    {
      "Sid": "SecretsManagerAccess",
      "Effect": "Allow",
      "Action": [
        "secretsmanager:GetSecretValue",
        "secretsmanager:DescribeSecret",
        "secretsmanager:CreateSecret",
        "secretsmanager:DeleteSecret",
        "secretsmanager:PutSecretValue",
        "secretsmanager:TagResource",
        "secretsmanager:GetResourcePolicy"
      ],
      "Resource": "arn:aws:secretsmanager:${AWS_REGION}:${AWS_ACCOUNT_ID}:secret:${ENVIRONMENT}/*"
    },
    {
      "Sid": "KMSForEncryption",
      "Effect": "Allow",
      "Action": [
        "kms:CreateKey",
        "kms:CreateAlias",
        "kms:DeleteAlias",
        "kms:DescribeKey",
        "kms:GetKeyPolicy",
        "kms:GetKeyRotationStatus",
        "kms:ListAliases",
        "kms:ListResourceTags",
        "kms:ScheduleKeyDeletion",
        "kms:TagResource",
        "kms:UntagResource",
        "kms:Encrypt",
        "kms:Decrypt",
        "kms:GenerateDataKey",
        "kms:CreateGrant",
        "kms:EnableKeyRotation",
        "kms:PutKeyPolicy"
      ],
      "Resource": "*"
    },
    {
      "Sid": "CloudWatchLogs",
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:DeleteLogGroup",
        "logs:DescribeLogGroups",
        "logs:PutRetentionPolicy",
        "logs:TagLogGroup",
        "logs:ListTagsLogGroup",
        "logs:TagResource",
        "logs:ListTagsForResource"
      ],
      "Resource": "*"
    },
    {
      "Sid": "AutoScaling",
      "Effect": "Allow",
      "Action": [
        "autoscaling:*"
      ],
      "Resource": "*"
    },
    {
      "Sid": "STSForEKS",
      "Effect": "Allow",
      "Action": [
        "sts:GetCallerIdentity"
      ],
      "Resource": "*"
    },
    {
      "Sid": "FortiWebInstanceProfile",
      "Effect": "Allow",
      "Action": [
        "iam:CreateInstanceProfile",
        "iam:DeleteInstanceProfile",
        "iam:GetInstanceProfile",
        "iam:AddRoleToInstanceProfile",
        "iam:RemoveRoleFromInstanceProfile",
        "iam:TagInstanceProfile"
      ],
      "Resource": "arn:aws:iam::${AWS_ACCOUNT_ID}:instance-profile/${PROJECT_NAME}-*-fortiweb"
    },
    {
      "Sid": "Route53Management",
      "Effect": "Allow",
      "Action": [
        "route53:CreateHostedZone",
        "route53:DeleteHostedZone",
        "route53:GetHostedZone",
        "route53:GetDNSSEC",
        "route53:ListHostedZones",
        "route53:ListHostedZonesByName",
        "route53:GetHostedZoneCount",
        "route53:ChangeResourceRecordSets",
        "route53:ListResourceRecordSets",
        "route53:GetChange",
        "route53:ChangeTagsForResource",
        "route53:ListTagsForResource",
        "route53:GetReusableDelegationSet",
        "route53:ListReusableDelegationSets"
      ],
      "Resource": "*"
    }
  ]
}
EOF
)

  # Create the custom policy
  POLICY_ARN=$(aws iam create-policy \
    --policy-name "${POLICY_NAME}" \
    --policy-document "${POLICY_DOCUMENT}" \
    --query 'Policy.Arn' \
    --output text)

  # Attach the custom policy (least-privilege, not AdministratorAccess)
  aws iam attach-role-policy \
    --role-name "${OIDC_ROLE_NAME}" \
    --policy-arn "${POLICY_ARN}"

  log_info "Created IAM role: ${OIDC_ROLE_NAME}"
  log_info "Attached least-privilege policy: ${POLICY_NAME}"
fi

# -----------------------------------------------------------------------------
# Step 5: Set GitHub Repository Secrets
# -----------------------------------------------------------------------------
log_info "Step 5: Setting GitHub repository secrets..."

# Check if repo exists (should already exist - user must push code first)
if ! gh repo view "${GITHUB_ORG}/${GITHUB_REPO}" &>/dev/null; then
  log_error "Repository ${GITHUB_ORG}/${GITHUB_REPO} not found."
  log_error "Please create the repo and push your code before running hydrate.sh"
  exit 1
fi

# Set secrets for OIDC authentication
gh secret set AWS_ROLE_ARN --body "${ROLE_ARN}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
gh secret set AWS_REGION --body "${AWS_REGION}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"

# Set secrets for Terraform backend configuration
# These are used by terraform init -backend-config in GitHub Actions
gh secret set TF_STATE_BUCKET --body "${STATE_BUCKET}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
gh secret set TF_STATE_KEY --body "eks/${ENVIRONMENT}/terraform.tfstate" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
gh secret set TF_LOCK_TABLE --body "${LOCK_TABLE}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"

log_info "GitHub secrets configured (AWS_ROLE_ARN, AWS_REGION, TF_STATE_BUCKET, TF_STATE_KEY, TF_LOCK_TABLE)"

# -----------------------------------------------------------------------------
# Step 6: Capture Admin IP for Security Group Access
# -----------------------------------------------------------------------------
log_info "Step 6: Capturing your public IP for admin access..."

ADMIN_IP=$(curl -s https://checkip.amazonaws.com | tr -d '\n')
if [[ -z "$ADMIN_IP" ]]; then
  log_error "Failed to detect public IP. Check your internet connection."
  exit 1
fi

ADMIN_CIDR="${ADMIN_IP}/32"
log_info "Your public IP: ${ADMIN_IP}"

# Set as GitHub secret for Terraform to use
gh secret set TF_VAR_admin_cidr --body "${ADMIN_CIDR}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
log_info "Set GitHub secret TF_VAR_admin_cidr=${ADMIN_CIDR}"

echo ""
echo "This IP will be used for:"
echo "  - EKS API public access"
echo "  - FortiWeb management console access"
echo ""
echo "To update your IP later, run:"
echo "  NEW_IP=\$(curl -s https://checkip.amazonaws.com)"
echo "  gh secret set TF_VAR_admin_cidr --body \"\${NEW_IP}/32\" --repo ${GITHUB_ORG}/${GITHUB_REPO}"
echo "  gh workflow run terraform.yml"
echo ""

# -----------------------------------------------------------------------------
# Step 6b: Capture Admin IAM Role for kubectl Access
# -----------------------------------------------------------------------------
log_info "Step 6b: Detecting your IAM role for kubectl access..."

# Get current caller identity and convert assumed-role ARN to role ARN
# assumed-role ARN: arn:aws:sts::123456789012:assumed-role/RoleName/SessionName
# role ARN:         arn:aws:iam::123456789012:role/path/RoleName
CALLER_ARN=$(aws sts get-caller-identity --query 'Arn' --output text)

if [[ "$CALLER_ARN" == *":assumed-role/"* ]]; then
  # Extract role name and construct the IAM role ARN
  ROLE_PATH_AND_NAME=$(echo "$CALLER_ARN" | sed 's|.*:assumed-role/||; s|/[^/]*$||')

  # Look up the actual role to get its full path
  ADMIN_ROLE_ARN=$(aws iam list-roles --query "Roles[?ends_with(Arn, '/${ROLE_PATH_AND_NAME}')].Arn | [0]" --output text 2>/dev/null || true)

  if [[ -z "$ADMIN_ROLE_ARN" || "$ADMIN_ROLE_ARN" == "None" ]]; then
    # Fallback: construct ARN assuming no path prefix
    ADMIN_ROLE_ARN="arn:aws:iam::${AWS_ACCOUNT_ID}:role/${ROLE_PATH_AND_NAME}"
  fi
elif [[ "$CALLER_ARN" == *":user/"* ]]; then
  log_warn "You're using an IAM user, not a role. kubectl access will use the user ARN."
  ADMIN_ROLE_ARN="$CALLER_ARN"
else
  ADMIN_ROLE_ARN="$CALLER_ARN"
fi

log_info "Admin role ARN: ${ADMIN_ROLE_ARN}"

# Set as GitHub secret for Terraform to use
gh secret set TF_VAR_admin_role_arn --body "${ADMIN_ROLE_ARN}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
log_info "Set GitHub secret TF_VAR_admin_role_arn"

echo ""
echo "This role will have cluster-admin access to EKS for kubectl commands."
echo ""

# Prompt for additional cluster admins
echo "Additional cluster admins (optional):"
echo "  - EKS uses API-only mode: only explicitly granted principals have access"
echo "  - Your role above is already included"
echo "  - Enter additional IAM ARNs (comma-separated) or leave blank"
echo ""
echo "  Example: arn:aws:iam::123456789012:role/DevOps,arn:aws:iam::123456789012:user/alice"
read -p "  Additional admin ARNs [none]: " ADDITIONAL_ADMINS_INPUT

if [[ -n "$ADDITIONAL_ADMINS_INPUT" ]]; then
  # Convert comma-separated string to JSON array for Terraform
  ADDITIONAL_ADMINS_JSON=$(echo "$ADDITIONAL_ADMINS_INPUT" | tr ',' '\n' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | jq -R . | jq -s .)
  gh secret set TF_VAR_additional_cluster_admins --body "${ADDITIONAL_ADMINS_JSON}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
  log_info "Set GitHub secret TF_VAR_additional_cluster_admins"
else
  # Set empty array
  gh secret set TF_VAR_additional_cluster_admins --body "[]" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
  log_info "No additional cluster admins configured"
fi

# -----------------------------------------------------------------------------
# Step 6c: FortiFlex Token for FortiWeb Licensing (Optional)
# -----------------------------------------------------------------------------
log_info "Step 6c: FortiFlex token configuration..."

echo ""
echo "FortiFlex licensing for FortiWeb (optional):"
echo "  - Leave blank for PAYG (pay-as-you-go via AWS Marketplace)"
echo "  - Enter token for FortiFlex/BYOL licensing"
read -p "  FortiFlex Token [skip]: " FORTIFLEX_TOKEN

if [[ -n "$FORTIFLEX_TOKEN" ]]; then
  gh secret set TF_VAR_fortiflex_token --body "${FORTIFLEX_TOKEN}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
  log_info "Set GitHub secret TF_VAR_fortiflex_token"
else
  # Delete any existing secret to ensure clean state
  gh secret delete TF_VAR_fortiflex_token --repo "${GITHUB_ORG}/${GITHUB_REPO}" 2>/dev/null || true
  log_info "Skipped FortiFlex token (using PAYG or manual licensing)"
fi

# -----------------------------------------------------------------------------
# Step 6d: DNS Configuration
# -----------------------------------------------------------------------------
log_info "Step 6d: DNS configuration..."

# Only prompt if not already set in configuration section
if [[ -z "$DOMAIN_NAME" ]]; then
  echo ""
  echo "DNS Configuration:"
  echo "  - Domain name for Route53 hosted zone and external-dns"
  echo "  - ACME email for Let's Encrypt certificate notifications"
  echo ""

  read -p "  Domain name [amerintlxperts.com]: " DOMAIN_NAME_INPUT
  DOMAIN_NAME="${DOMAIN_NAME_INPUT:-amerintlxperts.com}"
fi

if [[ -z "$ACME_EMAIL" ]]; then
  read -p "  ACME email [admin@${DOMAIN_NAME}]: " ACME_EMAIL_INPUT
  ACME_EMAIL="${ACME_EMAIL_INPUT:-admin@${DOMAIN_NAME}}"
fi

gh secret set TF_VAR_domain_name --body "${DOMAIN_NAME}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
gh secret set TF_VAR_acme_email --body "${ACME_EMAIL}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"

log_info "Set GitHub secrets TF_VAR_domain_name=${DOMAIN_NAME}, TF_VAR_acme_email=${ACME_EMAIL}"

# -----------------------------------------------------------------------------
# Step 6e: Reusable Delegation Set (Optional)
# -----------------------------------------------------------------------------
log_info "Step 6e: Reusable delegation set configuration..."

echo ""
echo "Reusable Delegation Set (optional but recommended):"
echo "  - Provides FIXED Route53 nameservers that never change"
echo "  - Without this, nameservers change on each terraform destroy/apply"
echo "  - You only need to update your domain registrar ONCE"
echo ""

if [[ -n "$DELEGATION_SET_ID" ]]; then
  log_info "Using pre-configured delegation set: ${DELEGATION_SET_ID}"
  gh secret set TF_VAR_delegation_set_id --body "${DELEGATION_SET_ID}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
  log_info "Set GitHub secret TF_VAR_delegation_set_id=${DELEGATION_SET_ID}"
else
  read -p "  Create reusable delegation set? [Y/n]: " CREATE_DELEGATION_SET
  CREATE_DELEGATION_SET="${CREATE_DELEGATION_SET:-y}"

  if [[ "${CREATE_DELEGATION_SET,,}" == "y" || "${CREATE_DELEGATION_SET,,}" == "yes" ]]; then
    DELEGATION_SET_REF="${PROJECT_NAME}-${ENVIRONMENT}"

    # Check if one already exists
    EXISTING_SET=$(aws route53 list-reusable-delegation-sets \
      --query "DelegationSets[?CallerReference=='${DELEGATION_SET_REF}'].Id" \
      --output text 2>/dev/null || true)

    if [[ -n "$EXISTING_SET" && "$EXISTING_SET" != "None" ]]; then
      DELEGATION_SET_ID=$(echo "$EXISTING_SET" | sed 's|/delegationset/||')
      log_info "Found existing delegation set: ${DELEGATION_SET_ID}"
    else
      log_info "Creating new reusable delegation set..."
      CREATE_RESULT=$(aws route53 create-reusable-delegation-set \
        --caller-reference "${DELEGATION_SET_REF}" \
        --output json 2>&1)

      if [[ $? -ne 0 ]]; then
        log_warn "Failed to create delegation set: ${CREATE_RESULT}"
        log_warn "Continuing without delegation set (nameservers will change on recreate)"
      else
        DELEGATION_SET_ID=$(echo "$CREATE_RESULT" | jq -r '.DelegationSet.Id' | sed 's|/delegationset/||')
        log_info "Created delegation set: ${DELEGATION_SET_ID}"
      fi
    fi

    if [[ -n "$DELEGATION_SET_ID" ]]; then
      # Get nameservers
      NAMESERVERS=$(aws route53 get-reusable-delegation-set \
        --id "${DELEGATION_SET_ID}" \
        --query 'DelegationSet.NameServers' \
        --output json)

      gh secret set TF_VAR_delegation_set_id --body "${DELEGATION_SET_ID}" --repo "${GITHUB_ORG}/${GITHUB_REPO}"
      log_info "Set GitHub secret TF_VAR_delegation_set_id=${DELEGATION_SET_ID}"

      echo ""
      echo "  ┌─────────────────────────────────────────────────────────────┐"
      echo "  │ IMPORTANT: Update your domain registrar's nameservers to:  │"
      echo "  └─────────────────────────────────────────────────────────────┘"
      echo "$NAMESERVERS" | jq -r '.[]' | while read ns; do echo "    - $ns"; done
      echo ""
      echo "  These nameservers will NEVER change, even after destroy/apply."
      echo ""
    fi
  else
    log_info "Skipped delegation set (nameservers will change on each recreate)"
    gh secret delete TF_VAR_delegation_set_id --repo "${GITHUB_ORG}/${GITHUB_REPO}" 2>/dev/null || true
  fi
fi

# -----------------------------------------------------------------------------
# Step 6f: Xperts htpasswd Authentication
# -----------------------------------------------------------------------------
log_info "Step 6f: Xperts htpasswd configuration..."

XPERTS_HTPASSWD_SECRET="${ENVIRONMENT}/xperts-htpasswd"

echo ""
echo "Xperts Basic Authentication (optional but recommended):"
echo "  - Protects ai and secops apps with username/password"
echo "  - Leave blank to skip (can be added later)"
echo ""

read -p "  Xperts username [skip]: " XPERTS_USERNAME

if [[ -n "$XPERTS_USERNAME" ]]; then
  # Prompt for password (hidden input)
  read -s -p "  Xperts password: " XPERTS_PASSWORD
  echo ""

  if [[ -z "$XPERTS_PASSWORD" ]]; then
    log_warn "Empty password provided, skipping htpasswd configuration"
  else
    # Check if htpasswd command is available
    if command -v htpasswd &> /dev/null; then
      HTPASSWD_ENTRY=$(htpasswd -nb "$XPERTS_USERNAME" "$XPERTS_PASSWORD")
    elif command -v openssl &> /dev/null; then
      # Fallback to openssl for generating APR1 hash
      HTPASSWD_ENTRY="${XPERTS_USERNAME}:$(openssl passwd -apr1 "$XPERTS_PASSWORD")"
    else
      log_error "Neither htpasswd nor openssl found. Please install apache2-utils or openssl."
      exit 1
    fi

    # Build JSON with both plaintext (for verification) and hash (for nginx)
    SECRET_JSON=$(jq -n \
      --arg user "$XPERTS_USERNAME" \
      --arg pass "$XPERTS_PASSWORD" \
      --arg htpasswd "$HTPASSWD_ENTRY" \
      '{username: $user, password: $pass, htpasswd: $htpasswd}')

    # Create or update the secret in AWS Secrets Manager
    if aws secretsmanager describe-secret --secret-id "${XPERTS_HTPASSWD_SECRET}" --region "${AWS_REGION}" 2>/dev/null; then
      log_info "Updating existing secret: ${XPERTS_HTPASSWD_SECRET}"
      aws secretsmanager put-secret-value \
        --secret-id "${XPERTS_HTPASSWD_SECRET}" \
        --secret-string "${SECRET_JSON}" \
        --region "${AWS_REGION}"
    else
      log_info "Creating secret: ${XPERTS_HTPASSWD_SECRET}"
      aws secretsmanager create-secret \
        --name "${XPERTS_HTPASSWD_SECRET}" \
        --description "htpasswd for xperts basic authentication (ai and secops)" \
        --secret-string "${SECRET_JSON}" \
        --region "${AWS_REGION}" \
        --tags Key=Project,Value="${PROJECT_NAME}" Key=Environment,Value="${ENVIRONMENT}" Key=ManagedBy,Value="hydrate.sh"
    fi

    log_info "Created/updated secret: ${XPERTS_HTPASSWD_SECRET}"
  fi
else
  log_info "Skipped xperts htpasswd configuration"
fi

# -----------------------------------------------------------------------------
# Step 6g: GitHub Container Registry Pull Secret
# -----------------------------------------------------------------------------
log_info "Step 6g: GitHub Container Registry pull secret configuration..."

GHCR_PULL_SECRET="${ENVIRONMENT}/ghcr-pull-secret"

echo ""
echo "GitHub Container Registry (ghcr.io) Pull Secret:"
echo "  - Required for pulling private container images from ghcr.io"
echo "  - Create a PAT at: https://github.com/settings/tokens"
echo "  - Required scope: read:packages"
echo "  - Leave blank to skip (can be added later)"
echo ""

read -p "  GitHub username for ghcr.io [skip]: " GHCR_USERNAME

if [[ -n "$GHCR_USERNAME" ]]; then
  read -s -p "  Personal Access Token (read:packages): " GHCR_TOKEN
  echo ""

  if [[ -z "$GHCR_TOKEN" ]]; then
    log_warn "Empty token provided, skipping ghcr.io pull secret"
  else
    # Create base64-encoded auth string
    AUTH_STRING=$(echo -n "${GHCR_USERNAME}:${GHCR_TOKEN}" | base64 -w0)

    # Create dockerconfigjson format
    DOCKER_CONFIG_JSON=$(cat <<EOFDC
{"auths":{"ghcr.io":{"auth":"${AUTH_STRING}"}}}
EOFDC
)

    # Create or update the secret in AWS Secrets Manager
    if aws secretsmanager describe-secret --secret-id "${GHCR_PULL_SECRET}" --region "${AWS_REGION}" 2>/dev/null; then
      log_info "Updating existing secret: ${GHCR_PULL_SECRET}"
      aws secretsmanager put-secret-value \
        --secret-id "${GHCR_PULL_SECRET}" \
        --secret-string "${DOCKER_CONFIG_JSON}" \
        --region "${AWS_REGION}"
    else
      log_info "Creating secret: ${GHCR_PULL_SECRET}"
      aws secretsmanager create-secret \
        --name "${GHCR_PULL_SECRET}" \
        --description "Docker config for pulling private images from ghcr.io" \
        --secret-string "${DOCKER_CONFIG_JSON}" \
        --region "${AWS_REGION}" \
        --tags Key=Project,Value="${PROJECT_NAME}" Key=Environment,Value="${ENVIRONMENT}" Key=ManagedBy,Value="hydrate.sh"
    fi

    log_info "Created/updated secret: ${GHCR_PULL_SECRET}"
    echo ""
    echo "  To use in Kubernetes:"
    echo "    1. Create ExternalSecret to sync to your namespace"
    echo "    2. Add imagePullSecrets to your deployment"
  fi
else
  log_info "Skipped ghcr.io pull secret configuration"
fi

# -----------------------------------------------------------------------------
# Step 7: Generate ArgoCD Deploy Key for Git Repo Access
# -----------------------------------------------------------------------------
# Always recreate the deploy key to ensure GitHub and Secrets Manager are in sync.
# This prevents issues where the secret exists but the GitHub deploy key was deleted.
# -----------------------------------------------------------------------------
log_info "Step 7: Setting up ArgoCD deploy key for Git repo access..."

ARGOCD_SECRET_NAME="${ENVIRONMENT}/argocd-repo-ssh"

# Delete existing GitHub deploy key if present
EXISTING_KEY_ID=$(gh repo deploy-key list --repo "${GITHUB_ORG}/${GITHUB_REPO}" --json id,title \
  --jq '.[] | select(.title == "ArgoCD") | .id' 2>/dev/null || true)

if [[ -n "$EXISTING_KEY_ID" ]]; then
  log_info "Removing existing ArgoCD deploy key from GitHub (ID: ${EXISTING_KEY_ID})..."
  echo "y" | gh repo deploy-key delete "$EXISTING_KEY_ID" --repo "${GITHUB_ORG}/${GITHUB_REPO}" 2>/dev/null || true
fi

# Delete existing secret from Secrets Manager if present
if aws secretsmanager describe-secret --secret-id "${ARGOCD_SECRET_NAME}" --region "${AWS_REGION}" 2>/dev/null; then
  log_info "Removing existing secret from Secrets Manager: ${ARGOCD_SECRET_NAME}"
  aws secretsmanager delete-secret \
    --secret-id "${ARGOCD_SECRET_NAME}" \
    --force-delete-without-recovery \
    --region "${AWS_REGION}" 2>/dev/null || true
  # Brief pause to allow deletion to propagate
  sleep 2
fi

# Generate new ED25519 SSH key pair
log_info "Generating new ArgoCD SSH key pair..."
TEMP_KEY_DIR=$(mktemp -d)
ssh-keygen -t ed25519 -C "argocd-${PROJECT_NAME}-${ENVIRONMENT}" -f "${TEMP_KEY_DIR}/argocd-key" -N "" > /dev/null 2>&1

PRIVATE_KEY=$(cat "${TEMP_KEY_DIR}/argocd-key")
PUBLIC_KEY=$(cat "${TEMP_KEY_DIR}/argocd-key.pub")

# Add deploy key to GitHub repo
log_info "Adding deploy key to GitHub repo..."
gh repo deploy-key add "${TEMP_KEY_DIR}/argocd-key.pub" \
  --repo "${GITHUB_ORG}/${GITHUB_REPO}" \
  --title "ArgoCD"

# Capture the deploy key ID for reference
DEPLOY_KEY_ID=$(gh repo deploy-key list --repo "${GITHUB_ORG}/${GITHUB_REPO}" --json id,title \
  --jq '.[] | select(.title == "ArgoCD") | .id' 2>/dev/null | tail -1 || true)

log_info "Deploy key added to GitHub repo (ID: ${DEPLOY_KEY_ID})"

# Store private key in Secrets Manager
aws secretsmanager create-secret \
  --name "${ARGOCD_SECRET_NAME}" \
  --description "ArgoCD SSH private key for Git repo access" \
  --secret-string "${PRIVATE_KEY}" \
  --region "${AWS_REGION}" \
  --tags Key=Project,Value="${PROJECT_NAME}" Key=Environment,Value="${ENVIRONMENT}" Key=ManagedBy,Value="hydrate.sh"

log_info "Created secret: ${ARGOCD_SECRET_NAME}"

# Cleanup temp files
rm -rf "${TEMP_KEY_DIR}"

# -----------------------------------------------------------------------------
# Step 7b: Additional ArgoCD Repo Deploy Keys (Optional)
# -----------------------------------------------------------------------------
log_info "Step 7b: Additional repository deploy keys (optional)..."

echo ""
echo "Additional Private Repositories for ArgoCD:"
echo "  - ArgoCD can pull manifests from multiple private repos"
echo "  - Each repo needs its own deploy key"
echo "  - Enter repos as: owner/repo (comma-separated)"
echo "  - Example: amerintlxperts/app-cloud,amerintlxperts/app-secops"
echo ""

read -p "  Additional repos [none]: " ADDITIONAL_REPOS_INPUT

if [[ -n "$ADDITIONAL_REPOS_INPUT" ]]; then
  # Track all additional repo secrets for summary
  ADDITIONAL_REPO_SECRETS=()

  # Process each repo
  IFS=',' read -ra REPOS <<< "$ADDITIONAL_REPOS_INPUT"
  for REPO_FULL in "${REPOS[@]}"; do
    # Trim whitespace
    REPO_FULL=$(echo "$REPO_FULL" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')

    if [[ -z "$REPO_FULL" ]]; then
      continue
    fi

    # Extract owner and repo name
    REPO_OWNER=$(echo "$REPO_FULL" | cut -d'/' -f1)
    REPO_NAME=$(echo "$REPO_FULL" | cut -d'/' -f2)

    if [[ -z "$REPO_OWNER" || -z "$REPO_NAME" ]]; then
      log_warn "Invalid repo format: ${REPO_FULL} (expected owner/repo)"
      continue
    fi

    log_info "Setting up deploy key for ${REPO_FULL}..."

    # Secret name uses repo name (sanitized)
    REPO_SECRET_NAME="${ENVIRONMENT}/argocd-repo-${REPO_NAME}"

    # Delete existing GitHub deploy key if present
    EXISTING_KEY_ID=$(gh repo deploy-key list --repo "${REPO_FULL}" --json id,title \
      --jq '.[] | select(.title == "ArgoCD") | .id' 2>/dev/null || true)

    if [[ -n "$EXISTING_KEY_ID" ]]; then
      log_info "  Removing existing ArgoCD deploy key from GitHub..."
      echo "y" | gh repo deploy-key delete "$EXISTING_KEY_ID" --repo "${REPO_FULL}" 2>/dev/null || true
    fi

    # Delete existing secret from Secrets Manager if present
    if aws secretsmanager describe-secret --secret-id "${REPO_SECRET_NAME}" --region "${AWS_REGION}" 2>/dev/null; then
      log_info "  Removing existing secret from Secrets Manager..."
      aws secretsmanager delete-secret \
        --secret-id "${REPO_SECRET_NAME}" \
        --force-delete-without-recovery \
        --region "${AWS_REGION}" 2>/dev/null || true
      sleep 2
    fi

    # Generate new ED25519 SSH key pair
    TEMP_KEY_DIR=$(mktemp -d)
    ssh-keygen -t ed25519 -C "argocd-${REPO_NAME}" -f "${TEMP_KEY_DIR}/key" -N "" > /dev/null 2>&1

    PRIVATE_KEY=$(cat "${TEMP_KEY_DIR}/key")

    # Add deploy key to GitHub repo
    if gh repo deploy-key add "${TEMP_KEY_DIR}/key.pub" --repo "${REPO_FULL}" --title "ArgoCD" 2>/dev/null; then
      log_info "  Deploy key added to GitHub"
    else
      log_warn "  Failed to add deploy key to ${REPO_FULL} - check repo access"
      rm -rf "${TEMP_KEY_DIR}"
      continue
    fi

    # Store private key in Secrets Manager
    aws secretsmanager create-secret \
      --name "${REPO_SECRET_NAME}" \
      --description "ArgoCD SSH private key for ${REPO_FULL}" \
      --secret-string "${PRIVATE_KEY}" \
      --region "${AWS_REGION}" \
      --tags Key=Project,Value="${PROJECT_NAME}" Key=Environment,Value="${ENVIRONMENT}" Key=ManagedBy,Value="hydrate.sh" Key=Repository,Value="${REPO_FULL}"

    log_info "  Created secret: ${REPO_SECRET_NAME}"
    ADDITIONAL_REPO_SECRETS+=("${REPO_SECRET_NAME}")

    rm -rf "${TEMP_KEY_DIR}"
  done

  if [[ ${#ADDITIONAL_REPO_SECRETS[@]} -gt 0 ]]; then
    echo ""
    log_info "Additional repo deploy keys created:"
    for SECRET in "${ADDITIONAL_REPO_SECRETS[@]}"; do
      echo "    - ${SECRET}"
    done
    echo ""
    echo "  To use in ArgoCD, create Repository resources referencing these secrets."
  fi
else
  log_info "No additional repos configured"
fi

# -----------------------------------------------------------------------------
# Step 8: Save Configuration for Cleanup
# -----------------------------------------------------------------------------
# Note: IRSA role ARN is now injected by Terraform directly into the
# External Secrets Helm release, keeping AWS account ID out of Git.
log_info "Step 8: Saving configuration..."

CONFIG_FILE="${SCRIPT_DIR}/.hydration-config"
cat > "${CONFIG_FILE}" <<EOF
# Generated by hydrate.sh - used by cleanup.sh
# Do not edit manually
PROJECT_NAME="${PROJECT_NAME}"
ENVIRONMENT="${ENVIRONMENT}"
AWS_REGION="${AWS_REGION}"
AWS_ACCOUNT_ID="${AWS_ACCOUNT_ID}"
GITHUB_ORG="${GITHUB_ORG}"
GITHUB_REPO="${GITHUB_REPO}"
STATE_BUCKET="${STATE_BUCKET}"
LOCK_TABLE="${LOCK_TABLE}"
OIDC_ROLE_NAME="${OIDC_ROLE_NAME}"
OIDC_POLICY_NAME="${OIDC_ROLE_NAME}-policy"
DEPLOY_KEY_ID="${DEPLOY_KEY_ID:-}"
DOMAIN_NAME="${DOMAIN_NAME}"
ACME_EMAIL="${ACME_EMAIL}"
DELEGATION_SET_ID="${DELEGATION_SET_ID:-}"
HYDRATION_DATE="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
EOF

log_info "Saved config to ${CONFIG_FILE}"

# -----------------------------------------------------------------------------
# Summary
# -----------------------------------------------------------------------------
echo ""
log_info "=========================================="
log_info "Hydration complete!"
log_info "=========================================="
echo ""
echo "Resources created:"
echo "  - S3 Bucket:      ${STATE_BUCKET}"
echo "  - DynamoDB Table: ${LOCK_TABLE}"
echo "  - OIDC Provider:  token.actions.githubusercontent.com"
echo "  - IAM Role:       ${OIDC_ROLE_NAME}"
echo "  - IAM Policy:     ${OIDC_ROLE_NAME}-policy (least-privilege)"
echo "  - Secret:         ${ENVIRONMENT}/argocd-repo-ssh (Secrets Manager)"
echo "  - Deploy Key:     ArgoCD (GitHub repo)"
if [[ -n "${DELEGATION_SET_ID:-}" ]]; then
echo "  - Delegation Set: ${DELEGATION_SET_ID} (fixed nameservers)"
fi
echo ""
echo "Created by Terraform (first apply):"
echo "  - Secret:         ${ENVIRONMENT}/fortiweb (auto-generated password)"
echo ""
echo "Optional secrets (if configured above):"
echo "  - Secret:         ${ENVIRONMENT}/xperts-htpasswd (basic auth)"
echo "  - Secret:         ${ENVIRONMENT}/ghcr-pull-secret (container registry)"
echo "  - Secrets:        ${ENVIRONMENT}/argocd-repo-* (additional repo keys)"
echo ""
echo "GitHub secrets set:"
echo "  - AWS_ROLE_ARN"
echo "  - AWS_REGION"
echo "  - TF_STATE_BUCKET, TF_STATE_KEY, TF_LOCK_TABLE"
echo "  - TF_VAR_admin_cidr (${ADMIN_CIDR})"
echo "  - TF_VAR_admin_role_arn (for kubectl access)"
echo "  - TF_VAR_additional_cluster_admins (if provided)"
echo "  - TF_VAR_fortiflex_token (if provided)"
echo "  - TF_VAR_domain_name (${DOMAIN_NAME})"
echo "  - TF_VAR_acme_email (${ACME_EMAIL})"
if [[ -n "${DELEGATION_SET_ID:-}" ]]; then
echo "  - TF_VAR_delegation_set_id (${DELEGATION_SET_ID})"
fi
echo ""
echo "Note: AWS account ID is NOT stored in git-tracked files."
echo "      IRSA role ARN is injected by Terraform at deploy time."
echo "      Admin IP can be updated by re-running hydrate.sh or manually."
echo ""

# -----------------------------------------------------------------------------
# Step 9: Optionally Trigger Terraform Apply
# -----------------------------------------------------------------------------
TRIGGER_TERRAFORM="y"
read -p "Trigger Terraform Apply via GitHub Actions? [Y/n]: " TRIGGER_TERRAFORM
TRIGGER_TERRAFORM="${TRIGGER_TERRAFORM:-y}"

if [[ "${TRIGGER_TERRAFORM,,}" == "y" || "${TRIGGER_TERRAFORM,,}" == "yes" ]]; then
  log_info "Step 9: Triggering Terraform Apply via GitHub Actions..."

  # Check if a terraform workflow is already running
  IN_PROGRESS_RUN=$(gh run list --workflow=terraform.yml --repo "${GITHUB_ORG}/${GITHUB_REPO}" \
    --status in_progress --json databaseId --jq '.[0].databaseId' 2>/dev/null || true)

  QUEUED_RUN=$(gh run list --workflow=terraform.yml --repo "${GITHUB_ORG}/${GITHUB_REPO}" \
    --status queued --json databaseId --jq '.[0].databaseId' 2>/dev/null || true)

  if [[ -n "$IN_PROGRESS_RUN" ]]; then
    log_info "Terraform workflow already in progress (Run ID: ${IN_PROGRESS_RUN})"
    log_info "Watching existing workflow..."
    RUN_ID="$IN_PROGRESS_RUN"
  elif [[ -n "$QUEUED_RUN" ]]; then
    log_info "Terraform workflow already queued (Run ID: ${QUEUED_RUN})"
    log_info "Watching existing workflow..."
    RUN_ID="$QUEUED_RUN"
  else
    log_info "Triggering terraform.yml workflow..."
    gh workflow run terraform.yml --repo "${GITHUB_ORG}/${GITHUB_REPO}"

    # Wait for workflow to start
    sleep 5

    # Get the run ID
    RUN_ID=$(gh run list --workflow=terraform.yml --repo "${GITHUB_ORG}/${GITHUB_REPO}" --limit=1 --json databaseId --jq '.[0].databaseId')

    if [[ -z "$RUN_ID" ]]; then
      log_error "Failed to get workflow run ID"
      log_error "You can manually trigger it: gh workflow run terraform.yml"
      exit 1
    fi
  fi

  log_info "Workflow Run ID: ${RUN_ID}"
  log_info "Waiting for Terraform Apply to complete (this may take 15-25 minutes)..."
  log_info "You can also watch at: https://github.com/${GITHUB_ORG}/${GITHUB_REPO}/actions/runs/${RUN_ID}"
  log_info "Press Ctrl+C to stop watching (workflow will continue in background)"
  echo ""

  # Use a trap to detect Ctrl+C (SIGINT)
  # gh run watch returns exit code 1 for BOTH workflow failure AND Ctrl+C
  # so we need to track whether the user interrupted
  USER_INTERRUPTED=false
  trap 'USER_INTERRUPTED=true' INT

  # Wait for the workflow to complete
  set +e
  gh run watch "${RUN_ID}" --repo "${GITHUB_ORG}/${GITHUB_REPO}" --exit-status
  WATCH_EXIT_CODE=$?
  set -e

  # Restore default INT handler
  trap - INT

  if [[ "$USER_INTERRUPTED" == "true" ]]; then
    # User pressed Ctrl+C
    echo ""
    log_warn "Stopped watching. Workflow continues in background."
    echo ""
    echo "To check status later:"
    echo "  gh run view ${RUN_ID} --repo ${GITHUB_ORG}/${GITHUB_REPO}"
    echo ""
    echo "To watch again:"
    echo "  gh run watch ${RUN_ID} --repo ${GITHUB_ORG}/${GITHUB_REPO}"
    echo ""
    echo "After workflow completes, configure kubectl:"
    echo "  aws eks update-kubeconfig --region ${AWS_REGION} --name ${PROJECT_NAME}-${ENVIRONMENT}"
  elif [[ $WATCH_EXIT_CODE -eq 0 ]]; then
    log_info "Terraform Apply completed successfully!"
    echo ""
    echo "Your infrastructure is now deployed. Next steps:"
    echo "  1. Configure kubectl:"
    echo "     aws eks update-kubeconfig --region ${AWS_REGION} --name ${PROJECT_NAME}-${ENVIRONMENT}"
    echo ""
    echo "  2. Verify the cluster:"
    echo "     kubectl get nodes"
    echo ""
    echo "  3. Access ArgoCD:"
    echo "     kubectl port-forward svc/argocd-server -n argocd 8080:443"
    echo "     Password: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d"
  else
    # Non-zero exit and not interrupted = workflow failed
    log_error "Terraform Apply workflow failed!"
    log_error "Check the logs: gh run view ${RUN_ID} --repo ${GITHUB_ORG}/${GITHUB_REPO} --log-failed"
    exit 1
  fi
else
  log_info "Skipping Terraform Apply"
  echo ""
  echo "Next steps:"
  echo "  1. Trigger Terraform manually:"
  echo "     gh workflow run terraform.yml --repo ${GITHUB_ORG}/${GITHUB_REPO}"
  echo ""
  echo "  2. Or run locally (requires AWS credentials):"
  echo "     cd terraform/environments/${ENVIRONMENT}"
  echo "     terraform init && terraform apply"
fi
echo ""
